{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check [Week 3 challenge description](../../challenges/week3.md) if you missed the required setup steps for this week.\n",
    "\n",
    "**ðŸ‘‰ Note that this notebook has typos and errors that you need to fix as a part of the challenge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the machine-generated images of pets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be working on a set of machine-generated images of the most popular (again, accordingly to the GenAI) breeds of cats and dogs. Images are stored in the folder [../data/pets/](../data/pets/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_images='../data/pets'\n",
    "\n",
    "img = PILImage.open(dir_images+'21_Ragdoll.webp')\n",
    "display(img.resize((400, 400)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get image [embeddings](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/vectors-vector-embeddings-and-metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use `ResNet50V2` model from https://keras.io/api/applications/#available-models to get embeddings of the images.\n",
    "\n",
    "Ignore possible information `I` and warning `W` messages from the first `tensorflow` import below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image as tf_image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = ResNet50V2(include_top=False, weights='imagenet', pooling='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model ResNet50V2 will be downloaded during the first instantiation to the folder `~/.keras/models/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh ~/.keras/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up processing a bit you will reduce the size of the images by half `1024//2`. Please note the use of `//` to have integer number as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get embeddings\n",
    "\n",
    "def get_image_embedding(model, img_path):\n",
    "    img = tf_image.load_img(img_path, target_size=(1024//2, 1024/2))\n",
    "    x = tf_image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    embeddings = model.predict(x)  \n",
    "    result = pd.DataFrame(embeddings[0]).T\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get embeddings for all images in the source directory and store them in the `embedding_df` Pandas DataFrame for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_images='../data/pets/'\n",
    "\n",
    "path_images = os.listdir(dir_images)\n",
    "embedding_df = pd.DataFrame()\n",
    "for current_img in tqdm(path_images):\n",
    "    curr_df = get_image_embedding(model=mymodel, img_path=dir_images+current_img)\n",
    "    curr_df['image'] = current_img\n",
    "    embedding_df = pd.concat([embedding_df, curr_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check one of the generated embeddings\n",
    "display(embedding_df.iloc[0])\n",
    "\n",
    "# Note 2048 fileds with real numbers for dimensions from 0 to 2047, plus the file name in the last field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload into your SAP HANA database\n",
    "\n",
    "...similarly to how you uploaded word vectors during the Week 2 exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HDB_USE_IDENTITY\"]=os.getenv(\"WORKSPACE_ID\")\n",
    "print(os.getenv(\"HDB_USE_IDENT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml import dataframe as hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myconn=hdf.ConnectionContext(userkey='yourDevChallenger')\n",
    "print(\"SAP HANA DB version: \", myconn.hana_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_table=\"IMAGES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myconn.connection.setautocommit(True)\n",
    "mycursor = myconn.connection.cursor()\n",
    "\n",
    "try:\n",
    "    mycursor.execute(f'DROP TABLE {source_table}')\n",
    "    myconn.connection.commit()\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any exceptions and possibly rollback the transaction\n",
    "    myconn.connection.rollback()\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table `IMAGES` will store:\n",
    "- a file name in `\"IMAGE_NAME\"`\n",
    "- a breed name in `\"NAME\"`\n",
    "- an **i**mage embedding (or **v**ector) in `\"IV\"`\n",
    "- a Base64-encoded image of a pet in `\"IMAGE\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myconn.create_table(\n",
    "    source_table, \n",
    "    table_structure={\n",
    "        \"IMAGE_NAME\": \"NVARCHAR(50)\", \n",
    "        \"NAME\": \"NVARCHAR(50)\", \n",
    "        \"IV\": \"TRUE_VECTOR(2048)\",\n",
    "        \"IMAGE\": \"NCLOB\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get image Base64 encodings to be stored in the database table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to open and encode an image to Base64\n",
    "def get_image_encoding(image_path, size=(400, 400)):\n",
    "    img_resized = PILImage.open(image_path).resize(size)\n",
    "    buffer = BytesIO()\n",
    "    img_resized.save(buffer, format=\"WEBP\")\n",
    "    encoded_img = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    return encoded_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, prepare the list of records `myrecords_to_insert` to be inserted into the database.\n",
    "\n",
    "Each record has 4 fields with:\n",
    "- a file name: `[myrow[-1:][0]`\n",
    "- a breed name derived from a file name: `myrow[-1:][0].split('.')[0].split('_')[1]`\n",
    "- image encoding: `get_image_encoding(dir_images+myrow[-1:][0])` for an image read from the file name\n",
    "- a string representation of a vector embedding `str(myrow[:-1])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "my_embeddings=embedding_df.values.tolist()\n",
    "\n",
    "myrecords_to_insert=[\n",
    "    [myrow[-1:][0], \n",
    "    myrow[-1:][0].split('.')[0].split('_')[1], \n",
    "    get_image_encoding(dir_images+myrow[-1:][0]), \n",
    "    str(myrow[:-1])] \n",
    "    for myrow in my_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display one of the records to see its all 4 fields\n",
    "display(myrecords_to_insert[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "myconn.connection.setautocommit(False)\n",
    "cursor = myconn.connection.cursor()\n",
    "\n",
    "try:\n",
    "    mycursor.execute(f'TRUNCATE TABLE {source_table}')\n",
    "    # Use the executemany method to insert the data\n",
    "    cursor.executemany(f'''INSERT INTO {source_table} (\"IMAGE_NAME\", \"NAME\", \"IMAGE\", \"IV\") VALUES (?, ?, ?, ?)''', \n",
    "        myrecords_to_insert\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any exceptions and possibly rollback the transaction\n",
    "    myconn.connection.rollback()\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "try:\n",
    "    # Commit the transaction to save the changes\n",
    "    myconn.connection.commit()\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and the connection when done\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data in the database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the size of the table in the database\n",
    "print(f\"Number of records in the table {source_table}: {myconn.table(table=source_table).count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display a record for one of the entries\n",
    "word='MaineCoon'\n",
    "\n",
    "sql = f'''\n",
    "SELECT \"A\".* FROM {source_table} AS \"A\"\n",
    "WHERE \"A\".\"NAME\"='{word}'\n",
    "'''\n",
    "\n",
    "hdf = myconn.sql(sql)\n",
    "print(hdf.select_statement)\n",
    "hdf.head(3).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `\"IV\"` column is binary and can be represented in different formats in different database client tools, as mentioned by Dirk O. in his comment: https://community.sap.com/t5/application-development-discussions/questions-re-quot-multi-model-with-sap-hana-cloud-quot-developer-challenge/m-p/13732043/highlight/true#M2028526\n",
    "\n",
    "It is only when transofrmed to the string with [`TO_NVARCHAR()`](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/to-nvarchar-function-data-type-conversion?version=2024_1_QRC&locale=en-US) then you can see its vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display a record for one of the entries\n",
    "word='MaineCoon'\n",
    "\n",
    "sql = f'''\n",
    "SELECT TO_VARCHAR(\"IV\") FROM {source_table} AS \"A\"\n",
    "WHERE \"A\".\"NAME\"='{word}'\n",
    "'''\n",
    "\n",
    "hdf = myconn.sql(sql)\n",
    "print(hdf.select_statement)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 180)\n",
    "hdf.head(3).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
