{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your SAP HANA database... \n",
    "\n",
    "...using the user key `myDevChallenger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaces-ws-cwf68\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# https://help.sap.com/docs/SAP_HANA_CLIENT/f1b440ded6144a54ada97ff95dac7adf/2dbfa39ecc364a65a6ab0fea9c8c8bd9.html?#secure-user-store-(hdbuserstore)-environment-variables\n",
    "\n",
    "os.environ[\"HDB_USE_IDENT\"]=os.getenv(\"WORKSPACE_ID\")\n",
    "print(os.getenv(\"HDB_USE_IDENT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql hana://userkey=myDevChallenger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closely related words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find 5 closest related words for **cat** and **CAT** using the [`COSINE_SIMILARITY()` SQL Function](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/cosine-similarity-063e1366a7d54735b98b2513ea4a88c9), but displaying the [`L2DISTANCE()`](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/l2distance) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hana://userkey=myDevChallenger\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>rn</th>\n",
       "            <th>word</th>\n",
       "            <th>related_word</th>\n",
       "            <th>similarity_score</th>\n",
       "            <th>l2distance</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1</td>\n",
       "            <td>cat</td>\n",
       "            <td>cats</td>\n",
       "            <td>0.8099379190125675</td>\n",
       "            <td>1.8781065954236473</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2</td>\n",
       "            <td>cat</td>\n",
       "            <td>dog</td>\n",
       "            <td>0.7609457161879546</td>\n",
       "            <td>2.081533633772025</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3</td>\n",
       "            <td>cat</td>\n",
       "            <td>kitten</td>\n",
       "            <td>0.7464984917354589</td>\n",
       "            <td>2.3034521897928815</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4</td>\n",
       "            <td>cat</td>\n",
       "            <td>feline</td>\n",
       "            <td>0.7326233654110104</td>\n",
       "            <td>2.25089669903064</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5</td>\n",
       "            <td>cat</td>\n",
       "            <td>beagle</td>\n",
       "            <td>0.7150583717655224</td>\n",
       "            <td>2.656861986457292</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1</td>\n",
       "            <td>CAT</td>\n",
       "            <td>CATS</td>\n",
       "            <td>0.4546213947726845</td>\n",
       "            <td>3.134979335832406</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2</td>\n",
       "            <td>CAT</td>\n",
       "            <td>IIMs</td>\n",
       "            <td>0.43279962543747347</td>\n",
       "            <td>4.325961126356552</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3</td>\n",
       "            <td>CAT</td>\n",
       "            <td>IIT</td>\n",
       "            <td>0.4209513456200335</td>\n",
       "            <td>3.6199560919359155</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4</td>\n",
       "            <td>CAT</td>\n",
       "            <td>MAT</td>\n",
       "            <td>0.41816407733538596</td>\n",
       "            <td>3.4067967527253344</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5</td>\n",
       "            <td>CAT</td>\n",
       "            <td>STAR</td>\n",
       "            <td>0.41086742330855963</td>\n",
       "            <td>3.862325675511875</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1, 'cat', 'cats', 0.8099379190125675, 1.8781065954236473),\n",
       " (2, 'cat', 'dog', 0.7609457161879546, 2.081533633772025),\n",
       " (3, 'cat', 'kitten', 0.7464984917354589, 2.3034521897928815),\n",
       " (4, 'cat', 'feline', 0.7326233654110104, 2.25089669903064),\n",
       " (5, 'cat', 'beagle', 0.7150583717655224, 2.656861986457292),\n",
       " (1, 'CAT', 'CATS', 0.4546213947726845, 3.134979335832406),\n",
       " (2, 'CAT', 'IIMs', 0.43279962543747347, 4.325961126356552),\n",
       " (3, 'CAT', 'IIT', 0.4209513456200335, 3.6199560919359155),\n",
       " (4, 'CAT', 'MAT', 0.41816407733538596, 3.4067967527253344),\n",
       " (5, 'CAT', 'STAR', 0.41086742330855963, 3.862325675511875)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT\n",
    "  RN,\n",
    "  WORD,\n",
    "  RELATED_WORD,\n",
    "  SIMILARITY_SCORE,\n",
    "  L2DISTANCE\n",
    "FROM (\n",
    "  SELECT\n",
    "    B.WORD AS WORD,\n",
    "    A.WORD AS RELATED_WORD,\n",
    "    COSINE_SIMILARITY(A.WV, B.WV) AS SIMILARITY_SCORE,\n",
    "    L2DISTANCE(A.WV, B.WV) AS L2DISTANCE,\n",
    "    ROW_NUMBER() OVER (PARTITION BY B.WORD ORDER BY COSINE_SIMILARITY(A.WV, B.WV) DESC) AS RN\n",
    "  FROM\n",
    "    \"DEVCHALLENGER\".\"GOOGLE_NEWS\" A,\n",
    "    (SELECT WV, WORD FROM \"DEVCHALLENGER\".\"GOOGLE_NEWS\" WHERE WORD IN ('cat', 'CAT')) B\n",
    "  WHERE\n",
    "    A.WORD <> B.WORD\n",
    ") AS RankedWords\n",
    "WHERE\n",
    "  RN <= 5\n",
    "ORDER BY\n",
    "  WORD DESC,\n",
    "  SIMILARITY_SCORE DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that **cat** is related to pets, and **CAT** is distantly related to some other acronyms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogy queries\n",
    "\n",
    "Having words represented at vectors you can run some vector computations on them, like the analogy queries. \n",
    "\n",
    "The famous example, described as well at Wikipedia, is [\"What is the word related to **queen**, if the word related to **king** is the **man**\"](https://en.wikipedia.org/wiki/Word2vec#Preservation_of_semantic_and_syntactic_relationships)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1='Bengaluru'\n",
    "related_word1='India'\n",
    "word2='Melbourne'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the mix of Python variables `word1`, `related_word1`, `word2` in the SQL statement below.\n",
    "\n",
    "The calculation of **3CosMul** presented in the [Linguistic Regularities in Sparse and Explicit Word Representations](https://aclanthology.org/W14-1618/) by Omer Levy, Yoav Goldberg is used in this SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hana://userkey=myDevChallenger\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>lookup_word</th>\n",
       "            <th>related_word</th>\n",
       "            <th>3COSMUL_SCORE</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Melbourne</td>\n",
       "            <td>Australia</td>\n",
       "            <td>1.048209669332026</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Melbourne', 'Australia', 1.048209669332026)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT \"V3\".\"WORD\" AS \"lookup_word\",\n",
    "       \"V4\".\"WORD\" AS \"related_word\",\n",
    "       ((1+ COSINE_SIMILARITY(\"V4\".\"WV\", \"V3\".\"WV\"))/2 * (1+COSINE_SIMILARITY(\"V4\".\"WV\", \"V2\".\"WV\"))/2) / ((1+COSINE_SIMILARITY(\"V4\".\"WV\", \"V1\".\"WV\"))/2 + 0.000001) AS \"3COSMUL_SCORE\"\n",
    "FROM \"DEVCHALLENGER\".\"GOOGLE_NEWS\" AS \"V4\"\n",
    "INNER JOIN \"DEVCHALLENGER\".\"GOOGLE_NEWS\" AS \"V1\" ON \"V1\".\"WORD\"=:word1\n",
    "INNER JOIN \"DEVCHALLENGER\".\"GOOGLE_NEWS\" AS \"V2\" ON \"V2\".\"WORD\"=:related_word1\n",
    "INNER JOIN \"DEVCHALLENGER\".\"GOOGLE_NEWS\" AS \"V3\" ON \"V3\".\"WORD\"=:word2\n",
    "WHERE \"V4\".\"WORD\"<>\"V2\".\"WORD\"\n",
    "  AND \"V4\".\"WORD\"<>\"V1\".\"WORD\"\n",
    "  AND \"V4\".\"WORD\"<>\"V3\".\"WORD\"\n",
    "ORDER BY 3 DESC\n",
    "LIMIT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiement with values of variables `word1`, `related_word1`, `word2` above to come up with your own example of the analogy query results and paste the screenshot in the submission thread: https://community.sap.com/t5/application-development-discussions/submissions-for-quot-sap-hana-cloud-multi-model-quot-developer-challenge/m-p/13728400#M2028459"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give you an initial idea: try `Monday`, `one`, `Tuesday` 🤓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, that:\n",
    "1. although it was tained on big amount of text, not all relationships, especally for topics having less coverage on Google News, might be capctured,\n",
    "2. you loaded only 100000 tokens (words and phrases) out of 3000000 from the original model, so although it should cover most common words, it might not include all words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
